{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd33237-568c-492d-951d-2eb84893798f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9679041 (36.92 MB)\n",
      "Trainable params: 9679041 (36.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 22440 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - ETA: 0s - loss: 0.5774 - accuracy: 0.6879Found 5610 images belonging to 2 classes.\n",
      "702/702 [==============================] - 1418s 2s/step - loss: 0.5774 - accuracy: 0.6879 - val_loss: 0.5304 - val_accuracy: 0.7337\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 1395s 2s/step - loss: 0.5051 - accuracy: 0.7459 - val_loss: 0.4738 - val_accuracy: 0.7763\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 1397s 2s/step - loss: 0.4454 - accuracy: 0.7929 - val_loss: 0.4837 - val_accuracy: 0.7747\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 1392s 2s/step - loss: 0.3987 - accuracy: 0.8212 - val_loss: 0.4279 - val_accuracy: 0.8043\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 1387s 2s/step - loss: 0.3457 - accuracy: 0.8518 - val_loss: 0.6125 - val_accuracy: 0.7829\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 1390s 2s/step - loss: 0.3032 - accuracy: 0.8733 - val_loss: 0.4284 - val_accuracy: 0.8242\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 1347s 2s/step - loss: 0.2655 - accuracy: 0.8939 - val_loss: 0.3413 - val_accuracy: 0.8513\n",
      "Epoch 8/10\n",
      "219/702 [========>.....................] - ETA: 13:08 - loss: 0.2315 - accuracy: 0.9082"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from PIL import Image, UnidentifiedImageError, ImageFile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "# Part 2: Data Preprocessing and Augmentation\n",
    "\n",
    "# Image Data Generators for training and validation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # 80% training, 20% validation split\n",
    ")\n",
    "\n",
    "# Define paths and image settings\n",
    "train_dir = '/Users/grose/Desktop/dog_cat_cleaned'\n",
    "target_size = (224, 224)  # Image size for the CNN model\n",
    "batch_size = 32\n",
    "\n",
    "# Custom generator to handle corrupt images\n",
    "def safe_flow_from_directory(datagen, directory, target_size, batch_size, class_mode, subset):\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        subset=subset\n",
    "    )\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            yield next(generator)  # Yield batch\n",
    "        except (OSError, UnidentifiedImageError) as e:\n",
    "            print(f\"Skipping corrupt image: {e}\")\n",
    "            continue  # Skip and move on to the next batch\n",
    "\n",
    "# Training and validation data generators\n",
    "train_generator = safe_flow_from_directory(\n",
    "    datagen, train_dir, target_size=target_size, batch_size=batch_size, class_mode='binary', subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = safe_flow_from_directory(\n",
    "    datagen, train_dir, target_size=target_size, batch_size=batch_size, class_mode='binary', subset='validation'\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = math.ceil(22440 / batch_size)  # Update 22440 with your actual training set size\n",
    "validation_steps = math.ceil(5610 / batch_size)  # Update 5610 with your actual validation set size\n",
    "\n",
    "# Part 3: Building a Custom CNN Model\n",
    "\n",
    "# Create the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),  # To prevent overfitting\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification (cats and dogs)\n",
    "])\n",
    "\n",
    "# Compile the CNN model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to see the structure\n",
    "model.summary()\n",
    "\n",
    "# Part 4: Training the Custom CNN Model\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the CNN model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=10,  # You can adjust this\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Part 5: Evaluating the CNN Model\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_acc = model.evaluate(validation_generator, steps=validation_steps)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_acc}\")\n",
    "\n",
    "# Part 6: Plotting Training and Validation Accuracy and Loss\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Plot the history\n",
    "plot_history(history)\n",
    "\n",
    "# Part 7: Confusion Matrix and Classification Report\n",
    "\n",
    "# Get true labels and predictions\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(validation_steps):\n",
    "    images, labels = next(validation_generator)\n",
    "    true_labels.extend(labels)\n",
    "    predictions = model.predict(images)\n",
    "    predicted_labels.extend(predictions > 0.5)  # Convert probabilities to binary predictions\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['cat', 'dog'], yticklabels=['cat', 'dog'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['cat', 'dog'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a0902-506f-4458-98c5-fe1119dd2de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
